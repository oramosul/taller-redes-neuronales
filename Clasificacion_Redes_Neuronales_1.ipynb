{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Clasificacion_Redes_Neuronales_1.ipynb","provenance":[{"file_id":"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/02_neural_network_classification_in_tensorflow.ipynb","timestamp":1653674455773}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JZNT-Tz4ntRw"},"source":["# Clasificación con Redes Neuronales (y Tensorflow)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ucRDjFFCJ92X"},"source":["## 1. Arquitectura típica de una red neuronal para clasificación\n","\n","Las partes comunes a todas las redes neuronales profundas son las siguientes:\n","* Capa de entrada\n","* Algunas capas ocultas\n","* Capa de salida\n","\n","Para el uso de redes neuronales para clasificación, es usual utilizar los siguientes elementos típicos.\n","\n","| **Elemento** | **Clasificación binaria** | **Clasificación multiclase** |\n","| --- | --- | --- |\n","| Capa de entrada  | Igual tamaño que el número de atributos | Similar a clasificación binaria |\n","| Capas ocultas | Mínimo 1, máximo ilimitado | Similar a clasificación binaria |\n","| Neuronas por capa oculta | Generalmente de 10 a 100 | Similar a clasificación binaria |\n","| Capa de salida | Tamaño 1 (una clase o la otra) | 1 por clase |\n","\n","Algunos otros elementos son los siguientes:\n","\n","| **Elemento** | **Clasificación binaria** | **Clasificación multiclase** |\n","| --- | --- | --- |\n","| Activación oculta | Usualmente ReLU (rectified linear unit) | Similar a clasificación binaria |\n","| Activación de salida | Sigmoidea | Softmax |\n","| Función de pérdida  | Entropía cruzada binaria (Cross entropy) | Entropía cruzada categórica |\n","| Optimizador | SGD (stochastic gradient descent), Adamk, etc. | Similar a clasificación binaria |"]},{"cell_type":"code","metadata":{"id":"IPWQMjYwKpCH"},"source":["import pandas as pd\n","from sklearn.datasets import make_circles\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEAjPGv8J2K0"},"source":["## 2. Creación de datos \n","\n","Por facilidad se utilizará la función `make_circles()` de Scikit-Learn.\n","\n"]},{"cell_type":"code","metadata":{"id":"7dT80sWqLYPf"},"source":["# Número de muestras\n","n_samples = 1000\n","# Crear círculos\n","X, y = make_circles(n_samples, noise = 0.03, random_state = 42)\n","\n","# Atributos\n","print(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FkgZlGstK572"},"source":["# Mostrar las 10 primeras etiquetas\n","print(y[:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzQ7X9QgMGpq"},"source":["# Crear un dataframe de atributos y etiquetas\n","circulos = pd.DataFrame({\"X0\":X[:, 0], \"X1\":X[:, 1], \"etiqueta\":y})\n","circulos.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cfgZGtMGe0XB"},"source":["# Verificar los valores de las etiquetas\n","circulos.etiqueta.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ajz7TdQPesKt"},"source":["Se tiene un problema de clasificación binaria ya que solo se tiene 2 etiquetas: 1 y 0"]},{"cell_type":"code","metadata":{"id":"KIPTzrETMemP"},"source":["# Visualización de los datos\n","plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Jty66H6cbJp"},"source":["Sería conveniente utilizar el [TensorFlow Playground](https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=2,2&seed=0.93799&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularization_hide=true&regularizationRate_hide=true&batchSize_hide=true) para ver experimentalmente el efecto de los componentes de una red neuronal. Intentar ajustar los diferentes hiperparámetros que se ve y hacer click a play para ver el entrenamiento de una red neuronal.\n"]},{"cell_type":"markdown","metadata":{"id":"Cv4fEHihOAq4"},"source":["**Tamaños de las entradas y salidas**"]},{"cell_type":"code","metadata":{"id":"lZxjjmsHNt_K"},"source":["# Verificar los tamaños de los atributos y de las etiquetas\n","print(X.shape)\n","print(y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwrSEVubgZNb"},"source":["# Primera instancia de atributos y de etiquetas\n","print(X[0])\n","print(y[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vSjUbiCBN9fc"},"source":["## 3. Modelamiento\n","\n","1. Crear el modelo\n","2. Compilar el modelo\n","3. Ajustar (entrenar) el modelo"]},{"cell_type":"code","metadata":{"id":"Lt4pbcZ7OEif"},"source":["# Semilla aleatoria\n","tf.random.set_seed(42)\n","\n","# 1. Creación del modelo\n","modelo_1 = tf.keras.Sequential([\n","                                tf.keras.layers.Dense(1)\n","])\n","\n","# 2. Compilar el modelo\n","modelo_1.compile(loss = tf.keras.losses.BinaryCrossentropy(),     # Solo 2 clases\n","                optimizer = tf.keras.optimizers.SGD(),\n","                metrics = ['accuracy'])\n","\n","# 3. Entrenamiento del modelo\n","modelo_1.fit(X, y, epochs=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqVVD_IqPHm5"},"source":["# Entrenamiento usando más épocas\n","modelo_1.fit(X, y, epochs=200, verbose=0) "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelo_1.evaluate(X, y)"],"metadata":{"id":"ekkN87PGxoZ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H-qaMmKrPegL"},"source":["**Mejoras**: Se puede añadir más capas"]},{"cell_type":"code","metadata":{"id":"TED0ZkOuPklW"},"source":["tf.random.set_seed(42)\n","\n","modelo_2 = tf.keras.Sequential([\n","                                tf.keras.layers.Dense(1), \n","                                tf.keras.layers.Dense(1) \n","])\n","\n","modelo_2.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n","                 optimizer = tf.keras.optimizers.SGD(),\n","                 metrics = ['accuracy'])\n","\n","historia = modelo_2.fit(X, y, epochs=100, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qFWWlhByirLa"},"source":["# Evaluate the model\n","modelo_2.evaluate(X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wyTs6QgijF6_"},"source":["## 4. Mejora del modelo\n","\n","Se puede realizar mejoras de manera similar a como se realiza en regresión."]},{"cell_type":"code","metadata":{"id":"46pebMB4Qeth"},"source":["tf.random.set_seed(42)\n","\n","modelo_3 = tf.keras.Sequential([\n","                               tf.keras.layers.Dense(100), # añadir 100 neuronas\n","                               tf.keras.layers.Dense(10),  # capa con 10 neuronas\n","                               tf.keras.layers.Dense(1)\n","])\n","\n","modelo_3.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n","                optimizer = tf.keras.optimizers.Adam(),  # Uso de Adam\n","                metrics = ['accuracy'])\n","\n","modelo_3.fit(X, y, epochs=100, verbose=0)   # Usar 100 pasadas por las datas"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluar el modelo\n","modelo_3.evaluate(X, y)"],"metadata":{"id":"w6JcRvYAzsyd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TJJL0YT7RVzv"},"source":["## 5. Visualización \n","\n","Cuando un modelo se comporta de manera extraña o hay algo que no parece correcto, lo usual es realizar una visualización para inspeccionar el modelo e inspeccionar las predicciones del modelo. \n","\n","Para visualizar, en este caso, se va a realizar una función `plot_decision_boundary()` que realizará lo siguiente:\n","* Tomar los atributos (X) y etiquetas como entrada (y)\n","* Crear una malla (meshgrid) de los valores de X\n","* Graficar las predicciones y la línea entre las diferentes zonas (donde se encuentra cada clase única)"]},{"cell_type":"code","metadata":{"id":"MuwGjU_XR0aG"},"source":["import numpy as np\n","\n","def plot_decision_boundary(model, X, y):\n","  \"\"\"\n","  Graficar la frontera de decisión \n","  \"\"\"\n","  # Definir los ejes de las fronteras y crear la malla\n","  x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n","  y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n","  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n","                       np.linspace(y_min, y_max, 100))\n","  \n","  # Crear los valores de X (se va a predecir para esos valores)\n","  x_in = np.c_[xx.ravel(), yy.ravel()]\n","  # Realizar las predicciones usando el modelo entrenado\n","  y_pred = model.predict(x_in)\n","\n","  # Verificar si es multi clase\n","  if model.output_shape[-1] > 1: # Verificar la dimensión final de la salida: si es > 1, es multi clase\n","    print(\"Realizando clasificación multiclase ...\")\n","    # Se tiene que modificar los tamaños de las predicciones para graficarlas\n","    y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n","  else:\n","    print(\"Realizando clasificación binaria...\")\n","    y_pred = np.round(np.max(y_pred, axis=1)).reshape(xx.shape)\n","  \n","  # Graficar la frontera de decisión\n","  plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n","  plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n","  plt.xlim(xx.min(), xx.max())\n","  plt.ylim(yy.min(), yy.max())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIyCVjolTmy4"},"source":["# Verificación sobre los datos\n","plot_decision_boundary(modelo_3, X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XIzcQrknUJPK"},"source":["El modelo intenta dibujar una línea a lo largo de los datos. Sin embargo los datos no son separables por una línea recta. En un problema de regresión, el problema puede funcionar, pero en clasificación no."]},{"cell_type":"markdown","metadata":{"id":"RZqShArhUh6d"},"source":["## 6. No linealidad\n","\n","Se puede añadir no linealidad al sistema introduciendo funciones de activación a la salida de las capas densas. Para esto se utilizará el parámetro `activation`."]},{"cell_type":"code","metadata":{"id":"utJIUKmHkbyV"},"source":["tf.random.set_seed(42)\n","\n","modelo_4 = tf.keras.Sequential([\n","                                tf.keras.layers.Dense(1, \n","                                                      activation = tf.keras.activations.relu), # similar a: activation='relu'\n","                                tf.keras.layers.Dense(1) # Capa de salida\n","])\n","\n","modelo_4.compile(loss = tf.keras.losses.binary_crossentropy,\n","                 optimizer = tf.keras.optimizers.Adam(),\n","                 metrics = [\"accuracy\"])\n","\n","history = modelo_4.fit(X, y, epochs=100, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluación del modelo\n","modelo_4.evaluate(X, y)"],"metadata":{"id":"uKgEF0EJ279g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para mejorar se añadirá capas a la red"],"metadata":{"id":"wdlu1eR73AZX"}},{"cell_type":"code","metadata":{"id":"yXxtQFHwlc9w"},"source":["tf.random.set_seed(42)\n","\n","modelo_5 = tf.keras.Sequential([\n","                                tf.keras.layers.Dense(4, activation = tf.keras.activations.relu), # capa oculta con 4 neuronas y ReLU\n","                                tf.keras.layers.Dense(4, activation = tf.keras.activations.relu), # capa oculta con 4 neuronas y ReLU\n","                                tf.keras.layers.Dense(1) # capa de salida\n","])\n","\n","modelo_5.compile(loss = tf.keras.losses.binary_crossentropy,\n","                optimizer = tf.keras.optimizers.Adam(lr=0.001), # Por defecto es 0.001\n","                metrics = ['accuracy'])\n","\n","history = modelo_5.fit(X, y, epochs=100, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJqimQ0UsiO5"},"source":["# Evaluate the model\n","modelo_5.evaluate(X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dh6l8egoc-Wr"},"source":["Aún se está en 50 % (el modelo está prácticamente adivinando). Es útil visualizar cómo se ven las predicciones"]},{"cell_type":"code","metadata":{"id":"OtmmuzJkcclw"},"source":["plot_decision_boundary(modelo_5, X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q-hj-lAodLYU"},"source":["Se añadirá una función de activación sigmoidea para la capa de salida. De hecho, en clasificación, una salida sigmoidea es usual."]},{"cell_type":"code","metadata":{"id":"zgyJ67E3corL"},"source":["tf.random.set_seed(42)\n","\n","modelo_6 = tf.keras.Sequential([\n","                                tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n","                                tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), \n","                                tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) # Activación sigmoidea\n","])\n","\n","modelo_6.compile(loss = tf.keras.losses.binary_crossentropy,\n","                optimizer = tf.keras.optimizers.Adam(),\n","                metrics = ['accuracy'])\n","\n","history = modelo_6.fit(X, y, epochs=100, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e5wpRgBVtSRK"},"source":["# Evaluate our model\n","modelo_6.evaluate(X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSoLyVMmczP4"},"source":["plot_decision_boundary(modelo_6, X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BPCpA90uQBjk"},"source":["## 7. Evaluación y mejora del modelo\n","\n","Se debe separar los datos en un conjunto de entrenamiento y evaluación (o prueba) y evaluar en el conjunto de evaluación"]},{"cell_type":"code","metadata":{"id":"NjOviFscgl4S"},"source":["# Elementos en el dataset\n","len(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNvKa8QrkSWR"},"source":["# Separación de datos\n","X_train, y_train = X[:800], y[:800] # 80% para entrenamiento\n","X_test, y_test = X[800:], y[800:]   # 20% para prueba\n","\n","X_train.shape, X_test.shape "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RUOBhA1g8Kx"},"source":["tf.random.set_seed(42)\n","\n","modelo_7 = tf.keras.Sequential([\n","  tf.keras.layers.Dense(4, activation=\"relu\"), \n","  tf.keras.layers.Dense(4, activation=\"relu\"),\n","  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","\n","modelo_7.compile(loss = tf.keras.losses.binary_crossentropy,\n","                 optimizer = tf.keras.optimizers.Adam(lr=0.01), # Incremento para que sea más rápido\n","                 metrics = ['accuracy'])\n","\n","history = modelo_7.fit(X_train, y_train, epochs=25)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aAnKqoDxloAA"},"source":["loss, accuracy = modelo_7.evaluate(X_test, y_test)\n","\n","print(f\"Pérdida en el conjunto de prueba: {loss}\")\n","print(f\"Exactitud en el conjunto de prueba: {100*accuracy:.2f}%\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c1lWpsNwjD5C"},"source":["Es conveniente una inspección visual\n"]},{"cell_type":"code","metadata":{"id":"LRvAIBfAmtdc"},"source":["plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.title(\"Entrenamiento\")\n","plot_decision_boundary(modelo_7, X=X_train, y=y_train)\n","plt.subplot(1, 2, 2)\n","plt.title(\"Prueba\")\n","plot_decision_boundary(modelo_7, X=X_test, y=y_test)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EqaFRxFaiklC"},"source":["**Curvas de pérdida**\n","\n","También son llamadas curvas de aprendizaje y muestran cómo se comporta el modelo durante el entrenamiento."]},{"cell_type":"code","metadata":{"id":"sBHuMm9mpoOz"},"source":["pd.DataFrame(history.history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqlwnZGJpYNF"},"source":["# Curvas\n","pd.DataFrame(history.history).plot();\n","plt.title(\"Curvas de pérdida para el modelo\");"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QyZA0CYLir5-"},"source":["**Factor de aprendizaje**"]},{"cell_type":"code","metadata":{"id":"3g05waDawhsZ"},"source":["tf.random.set_seed(42)\n","\n","modelo_8 = tf.keras.Sequential([\n","  tf.keras.layers.Dense(4, activation=\"relu\"),\n","  tf.keras.layers.Dense(4, activation=\"relu\"),\n","  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","\n","modelo_8.compile(loss = \"binary_crossentropy\",\n","                 optimizer = \"Adam\",\n","                 metrics = [\"accuracy\"]) \n","\n","# Callback para el factor de aprendizaje\n","#      Comenzar en 1e-4, e incrementar 10**(epoch/20) cada época\n","lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) \n","\n","history = modelo_8.fit(X_train, \n","                      y_train, \n","                      epochs = 100,\n","                      callbacks = [lr_scheduler], \n","                      verbose = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCd12upnyO4y"},"source":["pd.DataFrame(history.history).plot(figsize=(10,7), xlabel=\"epochs\");"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9OkUFgZSx6hP"},"source":["El factor de aprendizaje se incrementa exponencialmente con el número de épocas. La exactitud se incrementa en un punto específico cuando el factor de aprendizaje se incrementa lento. Se desea encontrar este punto. Para ello, se utilizará un gráfico en escala logarítmica."]},{"cell_type":"code","metadata":{"id":"8fnEklbYyGBG"},"source":["# Factor de aprendizaje vs Pérdida\n","lrs = 1e-4 * (10 ** (np.arange(100)/20))\n","\n","plt.figure(figsize=(10, 7))\n","plt.semilogx(lrs, history.history[\"loss\"]) # Eje x en escala logarítmica\n","plt.xlabel(\"Learning Rate\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Learning rate vs. loss\");"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iALar-WvPlEc"},"source":["Un factor de aprendizaje estimado idal es de aproximadamente 0.02. Se utilizará y se re entrenará un modelo."]},{"cell_type":"code","metadata":{"id":"EJ9wbXblzPPL"},"source":["tf.random.set_seed(42)\n","\n","modelo_9 = tf.keras.Sequential([\n","  tf.keras.layers.Dense(4, activation=\"relu\"),\n","  tf.keras.layers.Dense(4, activation=\"relu\"),\n","  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","\n","modelo_9.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(lr=0.02), \n","                metrics=[\"accuracy\"])\n","\n","history = modelo_9.fit(X_train, y_train, epochs=20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qb9xwISc0pnF"},"source":["Se llega a una exactitud alta con menos épocas (20 en lugar de 25)"]},{"cell_type":"code","metadata":{"id":"3ZCYAqitKUk2"},"source":["# Evaluar el modelo en el conjunto de prueba\n","modelo_9.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJbzQ5kQ2HSh"},"source":["plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.title(\"Entrenamiento\")\n","plot_decision_boundary(modelo_9, X=X_train, y=y_train)\n","plt.subplot(1, 2, 2)\n","plt.title(\"Prueba\")\n","plot_decision_boundary(modelo_9, X=X_test, y=y_test)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0bNdy1EbftYp"},"source":["### 8. Otras formas de evaluación\n","\n","La siguiente tabla muestra algunas de las métricas más usuales\n","\n","| **Métrica/método** | **Definición** | **Código** |\n","| --- | --- | --- |\n","| Exactitud | De cada 100 predicciones, cuántas son correctas | [`sklearn.metrics.accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) o [`tf.keras.metrics.Accuracy()`](tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy) |\n","| Precisión | Proporción de verdaderos positivos entre el total de muestras. | [`sklearn.metrics.precision_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) o [`tf.keras.metrics.Precision()`](tensorflow.org/api_docs/python/tf/keras/metrics/Precision) |\n","| Recall | Proporción de verdaderos positivos entre el total de verdaderos positivos y falsos negativos (predice 0 cuando es 1). | [`sklearn.metrics.recall_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) o [`tf.keras.metrics.Recall()`](tensorflow.org/api_docs/python/tf/keras/metrics/Recall) |\n","| F1-score | Combina precisión y recall. | [`sklearn.metrics.f1_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) |\n","| [Matriz de confusión | Compara los valores predichos con los reales en formato tabular | [`sklearn.metrics.plot_confusion_matrix()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) |\n"]},{"cell_type":"code","metadata":{"id":"LUvEwzqp4zVW"},"source":["# Exactitud del modelo\n","loss, accuracy = modelo_9.evaluate(X_test, y_test)\n","\n","print(f\"Pérdida: {loss}\")\n","print(f\"Exactitud: {(accuracy*100):.2f}%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_Zee4lI5vi2"},"source":["# Matriz de confusión\n","from sklearn.metrics import confusion_matrix\n","\n","# Make predictions\n","y_preds = modelo_9.predict(X_test)\n","\n","# Create a confusion matrix\n","confusion_matrix(y_test, tf.round(y_preds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIPSs9ERi78w"},"source":["import itertools\n","\n","figsize = (10, 10)\n","\n","# Crear la matriz de confusión\n","cm = confusion_matrix(y_test, tf.round(y_preds))\n","cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n","n_classes = cm.shape[0]\n","\n","fig, ax = plt.subplots(figsize=figsize)\n","cax = ax.matshow(cm, cmap=plt.cm.Blues) # https://matplotlib.org/3.2.0/api/_as_gen/matplotlib.axes.Axes.matshow.html\n","fig.colorbar(cax)\n","\n","classes = False\n","\n","if classes:\n","  labels = classes\n","else:\n","  labels = np.arange(cm.shape[0])\n","\n","ax.set(title=\"Matriz de Confusión\",\n","       xlabel=\"Etiquetas predichas\",\n","       ylabel=\"Etiquetas reales\",\n","       xticks=np.arange(n_classes),\n","       yticks=np.arange(n_classes),\n","       xticklabels=labels,\n","       yticklabels=labels)\n","\n","ax.xaxis.set_label_position(\"bottom\")\n","ax.xaxis.tick_bottom()\n","ax.xaxis.label.set_size(20)\n","ax.yaxis.label.set_size(20)\n","ax.title.set_size(20)\n","threshold = (cm.max() + cm.min()) / 2.\n","\n","for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","  plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n","           horizontalalignment=\"center\",\n","           color=\"white\" if cm[i, j] > threshold else \"black\",\n","           size=15)"],"execution_count":null,"outputs":[]}]}