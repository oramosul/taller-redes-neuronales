{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Regresion_Redes_Neuronales_1.ipynb","provenance":[{"file_id":"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/01_neural_network_regression_in_tensorflow.ipynb","timestamp":1653619107074}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UPgo18-N1gSi"},"source":["# Regresión usando Redes Neuronales y TensorFlow"]},{"cell_type":"markdown","metadata":{"id":"etAu7oCZ8r_G"},"source":["## 1. Arquitectura típica de una regresión usando redes neuronales\n","\n","Existen diferentes formas de realizar regresión usando redes neuronales. La siguiente tabla muestra los elementos típicos de una red neuronal que realiza regresión.\n","\n","| **Elemento** | **Valor típico** |\n","| --- | --- |\n","| Capa de entrada (tamaño) | Igual tamaño que el número de atributos  |\n","| Capa(s) Oculta(s) | Mínimo 1, máximo ilimitado |\n","| Neuronas por capa oculta | Generalmente entre 10 a 100 |\n","| Capa de salida (tamaño)  | Igual tamaño que la predicción deseada |\n","\n","Algunos otros elementos son los siguientes:\n","\n","| **Elemento** | **Valor típico** |\n","| --- | --- |\n","| Activación de la capa oculta | Usualmente ReLU (rectified linear unit) |\n","| Activación de la salida  | Puede ser ninguna, ReLU, sigmoidea, tanh |\n","| Función de pérdida | MSE (mean square error), MAE (mean absolute error) o una combinación MAE/MSE (si hay outliers) |\n","| Optimizador | SGD (stochastic gradient descent), Adam, etc. |\n","\n","Los elementos anteriores son hiperparámetros del sistema. Los hiperparámetros son valores cualitativos o cuantitativos que se tiene que establecer de manera arbitraria (el sistema no los aprende). Por otro lado, los parámetros suelen ser aquellos valores que el modelo aprende al ser entrenado."]},{"cell_type":"code","metadata":{"id":"FMqsqKpk7TrH"},"source":["# Importar tensorflow\n","import tensorflow as tf\n","\n","# Importar otras librerías\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Verificar la versión de tensorflow\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8clMYxrF6Mzv"},"source":["## 2. Datos de entrenamiento\n"]},{"cell_type":"code","source":["# Atributos (entradas)\n","X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n","# Etiquetas (salidas)\n","y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n","\n","print(X)\n","print(y)\n","\n","# tamaño de los tensores creados\n","print(X.shape)\n","print(y.shape)"],"metadata":{"id":"bact33p-kQHb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Atributos (entradas)\n","X = np.arange(-100, 100, 4)\n","# Etiquetas (salidas)\n","y = X + 10\n","\n","print(X)\n","print(y)"],"metadata":{"id":"FcGsuPAhrXFc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.1 Separación de datos en entrenamiento y prueba\n","\n","Una de las etapas más comunes consiste en crear un conjunto de entrenamiento (train) y de prueba (test). En algunos casos se puede utilizar, además, un conjunto de validación. Cada cojunto cumple una función específica:\n","\n","* **Conjunto de entrenamiento** - el modelo se entrena utilizando estos datos, los cuales on usualmente entre el 70-80% del total disponible.\n","* **Conjunto de validación** - el modelo se sintoniza con estos datos, y son típicamente el 10-15% del total disponible.\n","* **Conjunto de prueba** - el modelo se evalúa en estos datos para ver qué fue lo que aprendió. Usualmente comprende 10-15% del total de los datos dispoonibles.\n","\n","Por facilida, por ahora solo se utilizará en conjunto de entrenamiento y el de prueba. Ambos se pueden crear separando X, y."],"metadata":{"id":"dvDtLgh0twF4"}},{"cell_type":"code","source":["# Conjunto de entrenamiento (80%)\n","X_train = X[:40]\n","y_train = y[:40]\n","\n","# Conjunto de prueba (20%)\n","X_test = X[40:]\n","y_test = y[40:]\n","\n","len(X_train), len(X_test)"],"metadata":{"id":"lM7Jhs98u2o5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.2 Visualización de los datos"],"metadata":{"id":"kq08N0TcvVzw"}},{"cell_type":"code","source":["# plt.figure(figsize=(10, 7))\n","\n","# Conjunto de entrenamiento (azul)\n","plt.scatter(X_train, y_train, c='b', label='Conjunto de entrenamiento')\n","\n","# Conjunto de prueba (verde)\n","plt.scatter(X_test, y_test, c='g', label='Conjunto de prueba')\n","\n","# Mostrar la leyenda\n","plt.legend()"],"metadata":{"id":"K0OoEU9uvasa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adecuar el tamaño de X a lo requerido por tensorflow\n","# Xtf = tf.expand_dims(X, axis=-1)    # Adecúa la entrada a 2 dimensiones\n","# Xtf.shape"],"metadata":{"id":"Raqejr5UmSgO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PhAIqjrn6olF"},"source":["## 3. Modelamiento\n","\n","En TensorFlow hay 3 pasos fundamentales para crear y entrenar un modelo.\n","\n","1. **Crear el modelo** - consiste en crear las capas de una red neuronal usando el API [funcional](https://www.tensorflow.org/guide/keras/functional) o [secuencial](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)). Igualmente se puede importar un modelo previamente construido (\"transfer learning\")\n","\n","2. **Compilar el modelo** - consiste en definir cómo se va a medir el rendimiento del modelo (métricas, función de pérdida), así como en definir cómo va a mejorarse el modelo (usando algún otimizador). \n","\n","3. **Entrenar el modelo** - consiste en dejar que el modelo encuentre patrones en los datos (cómo las entradas se usan para generar las salidas). \n","\n","Aquí se utilizará el API secuencial de [Keras](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) para construir el modelo de regresión.\n"]},{"cell_type":"markdown","source":["### 3.1 Creación y compilación del modelo"],"metadata":{"id":"LoM__GGsxiFd"}},{"cell_type":"code","metadata":{"id":"P9jj-OE16yCn"},"source":["# Establecer una semilla aleatoria\n","tf.random.set_seed(42)\n","\n","# Crear un modelo con 1 sola capa densa cuyo tamaño de entrada es 1 (si no se \n","# especifica el tamaño, Keras trata de inferirlo)\n","model = tf.keras.Sequential([\n","                             tf.keras.layers.Dense(1, input_shape=[1])\n","])\n","\n","# Compilar el modelo\n","model.compile(loss = tf.keras.losses.mae,            # MAE como función de pérdida\n","              optimizer = tf.keras.optimizers.SGD(), # SGD como optimizador\n","              metrics = [\"mae\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se puede visualizar la estructura del modelo usando `summary()`, que muestra las capas que contiene, el tamaño de las salidas y el número de parámetros.\n","\n","* **Total params** - número total de parámetros del modelo\n","* **Trainable parameters** - parámetros que son actualizados al entrenar el modelo.\n","* **Non-trainable parameters** - parámetros que no son actualizados durante el entrenamiento (usualmente en transfer learning)."],"metadata":{"id":"qGEGSH47xRYd"}},{"cell_type":"code","source":["# Resumen del modelo\n","model.summary()"],"metadata":{"id":"usGTKwfzwEzV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vista en 2D del modelo\n","from tensorflow.keras.utils import plot_model\n","\n","plot_model(model, show_shapes=True)"],"metadata":{"id":"Q3m5gL6wyhta"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.2 Entrenamiento del modelo"],"metadata":{"id":"tvZanpWcyvH3"}},{"cell_type":"code","source":["# Se utilizará únicamente 5 épocas\n","model.fit(X_train, y_train, epochs=5)"],"metadata":{"id":"Ozu8BibUxcPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicciones para el conjunto de entrenamiento\n","y_pred_train = model.predict(X_train)\n","y_pred_train[1:5]"],"metadata":{"id":"zf2wG0bVybHZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plt.figure(figsize=(10, 7))\n","plt.scatter(X_train, y_train, c=\"b\", label=\"Datos de entrenamiento\")\n","plt.scatter(X_train, y_pred_train, c=\"g\", label=\"Predicciones\")\n","plt.plot(X_train, y_pred_train, c=\"g\")\n","plt.legend();"],"metadata":{"id":"FFa-6cQAmgnj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicciones para el conjunto de prueba\n","y_pred_test = model.predict(X_test)\n","\n","# Visualizacióon\n","plt.scatter(X_test, y_test, c=\"b\", label=\"Datos de prueba\")\n","plt.scatter(X_test, y_pred_test, c=\"g\", label=\"Predicciones\")\n","plt.plot(X_test, y_pred_test, c=\"g\")\n","plt.legend();"],"metadata":{"id":"r9zzMtD0m7q8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Evaluación de la prediccióon\n","\n","Algunas de las dos métricas más utilizadas para problemas de regresión son:\n","\n","* **Mean absolute error (MAE)** - promedio de la diferencia entre cada predicción.\n","* **Mean squared error (MSE)** - error cuadrático medio de las prediccioones\n","\n","También se puede utilizar [`model.evaluate()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate), que retorna la pérdida del modelo así como otras métricas especificadas durante el entrenamiento."],"metadata":{"id":"oSgpSrAb0Wc_"}},{"cell_type":"code","source":["# Evaluación en el conjunto de prueba\n","ev = model.evaluate(X_test, y_test)\n","\n","print(ev)"],"metadata":{"id":"HED9l4X_0WDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cálculo del MAE\n","mae = tf.metrics.mean_absolute_error(y_true=y_test, \n","                                     y_pred=y_pred_test.squeeze())\n","print(\"MAE:\", mae)\n","\n","# Cálculo del MSE\n","mse = tf.metrics.mean_squared_error(y_true=y_test,\n","                                    y_pred=y_pred_test.squeeze())\n","print(\"MSE:\", mse)"],"metadata":{"id":"xmRqytvJ5aJu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cálculo del MAE usando funciones de tensorflow\n","tf.reduce_mean(tf.abs(y_test-y_pred_test.squeeze()))"],"metadata":{"id":"cbTP1yz05Jv9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qAPk1T3xgOm4"},"source":["## 5. Mejora del modelo\n","\n","Para mejorar el modelo se modificará algunos de los hiper parámetros utilizados anteriormente. A continuación se indica qué se puede modificar en cada etapa.\n","\n","1. **Creación del modelo** - se puede añadir más capas, incrementar el número de neuronoas ocultas en cada capa, modificar las funciones de activación de cada capa.\n","2. **Compilación del modelo** - se puede utilizar otra función de optimización o modificar el factor de aprendizaje (\"learning rate\").\n","3. **Entrenamiento del modelo** - se puede utilizar más épocas (pasadas completas por los datos) o incrementar el número de datos.\n","\n","Aquí se entrenará tres modelos y se comparará los resultados.\n","\n","**a. Modelo 1**\n","\n","Este modelo solo tiene una capa y es entrenado usando 100 épocas"]},{"cell_type":"code","metadata":{"id":"StVHIIM9csyS"},"source":["tf.random.set_seed(42)\n","\n","# Similar al modeloo original\n","model_1 = tf.keras.Sequential([\n","                               tf.keras.layers.Dense(1, input_shape=[1])\n","])\n","\n","# Compilación del modelo\n","model_1.compile(loss = tf.keras.losses.mae,\n","                optimizer = tf.keras.optimizers.SGD(),\n","                metrics = ['mae'])\n","\n","# Entrenamiento: usando 100 épocas\n","model_1.fit(X_train, y_train, epochs=100, verbose=0);  # Verbose=0 elimina la salida"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-Da56xspOrY"},"source":["# Predicciones\n","y_preds_1 = model_1.predict(X_test)\n","\n","# Métricas\n","mae_1 = tf.metrics.mean_absolute_error(y_test, y_preds_1.squeeze())\n","mse_1 = tf.metrics.mean_squared_error(y_test, y_preds_1.squeeze())\n","print(\"MAE:\", mae_1.numpy(), \"\\nMSE:\", mse_1.numpy())\n","\n","# Visualización\n","plt.scatter(X_test, y_test, c=\"b\", label=\"Datos de prueba\")\n","plt.scatter(X_test, y_preds_1, c=\"g\", label=\"Predicciones\")\n","plt.plot(X_test, y_preds_1, c=\"g\")\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XXELOpdBrE9_"},"source":["**b. Modelo 2**\n","\n","Se añadirá otra capa densa (modelo con 2 capas), manteniendo todo lo demás constante."]},{"cell_type":"code","metadata":{"id":"05vcgEP3rEFi"},"source":["tf.random.set_seed(42)\n","\n","# Modelo con 2 capas\n","model_2 = tf.keras.Sequential([\n","                               tf.keras.layers.Dense(1, input_shape=[1]),\n","                               tf.keras.layers.Dense(1)\n","])\n","\n","# Compilación del modelo\n","model_2.compile(loss = tf.keras.losses.mae,\n","                optimizer = tf.keras.optimizers.SGD(),\n","                metrics = ['mae'])\n","\n","# Entrenamiento\n","model_2.fit(X_train, y_train, epochs=100, verbose=0);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9xCbDcoDraux"},"source":["# Predicciones\n","y_preds_2 = model_2.predict(X_test)\n","\n","# Métricas\n","mae_2 = tf.metrics.mean_absolute_error(y_test, y_preds_2.squeeze())\n","mse_2 = tf.metrics.mean_squared_error(y_test, y_preds_2.squeeze())\n","print(\"MAE:\", mae_2.numpy(), \"\\nMSE:\", mse_2.numpy())\n","\n","# Visualización\n","plt.scatter(X_test, y_test, c=\"b\", label=\"Datos de prueba\")\n","plt.scatter(X_test, y_preds_2, c=\"g\", label=\"Predicciones\")\n","plt.plot(X_test, y_preds_2, c=\"g\")\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R8i9yfQGrwHx"},"source":["**c. Modelo 3**\n","\n","Se mantendrá todo como en el modelo_2, pero se entrenará por más tiempo (500 épocas)"]},{"cell_type":"code","metadata":{"id":"ABGwQFsbrvUS"},"source":["tf.random.set_seed(42)\n","\n","# Similar a model_2\n","model_3 = tf.keras.Sequential([\n","                               tf.keras.layers.Dense(1, input_shape=[1]),\n","                               tf.keras.layers.Dense(1)\n","])\n","\n","model_3.compile(loss = tf.keras.losses.mae,\n","                optimizer = tf.keras.optimizers.SGD(),\n","                metrics = ['mae'])\n","\n","# Entrenamiento: usando 500 épocas\n","model_3.fit(X_train, y_train, epochs=500, verbose=0);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEz4bVmasbFk"},"source":["# Predicciones\n","y_preds_3 = model_3.predict(X_test)\n","\n","# Métricas\n","mae_3 = tf.metrics.mean_absolute_error(y_test, y_preds_3.squeeze())\n","mse_3 = tf.metrics.mean_squared_error(y_test, y_preds_3.squeeze())\n","print(\"MAE:\", mae_3.numpy(), \"\\nMSE:\", mse_3.numpy())\n","\n","# Visualización\n","plt.scatter(X_test, y_test, c=\"b\", label=\"Datos de prueba\")\n","plt.scatter(X_test, y_preds_3, c=\"g\", label=\"Predicciones\")\n","plt.plot(X_test, y_preds_3, c=\"g\")\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPEeM3UsrxGB"},"source":["### Comparación de resultados"]},{"cell_type":"code","metadata":{"id":"mw5RZk-BqLZd"},"source":["model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n","                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n","                 [\"model_3\", mae_3.numpy(), mae_3.numpy()]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ip7bKH83p5X0"},"source":["import pandas as pd\n","all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n","all_results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fe5DgNbX6192"},"source":["## 6. Almacenamiento y Carga de un Modelo\n","\n","En un modelo de TensorFlow/Keras se puede almacenaar un modelo usando [`model.save()`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model).\n","\n","Hay dos maneras de almacenar un modelo en TensorFlow:\n","1. El formato [SavedModel](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format) (default).\n","2. El formato [HDF5](https://www.tensorflow.org/tutorials/keras/save_and_load#hdf5_format).\n","\n","La diferencia principal entre ambos es que el SavedModel autoomáticamente puede almacenar objetos personalizados (como capas especiales) sin modificaciones al cargar el modelo.\n","\n","### 6.1. Almacenamiento"]},{"cell_type":"code","metadata":{"id":"gg0jD2cUoPsg"},"source":["# Almacenar un modelo utilizando el formato SavedModel\n","model_2.save('mejor_modelo_SavedModel')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dsCpDYrU7D1j"},"source":["# Verificar el modelo (archivo protobuf .pb)\n","!ls mejor_modelo_SavedModel"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NGKmWco_SOEU"},"source":["Now let's save the model in the HDF5 format, we'll use the same method but with a different filename."]},{"cell_type":"code","metadata":{"id":"97J6GJMBSM2j"},"source":["# Almacenar el modelo usando formato HDF5\n","model_2.save(\"mejor_modelo_HDF5.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vB7TmsSGSjdv"},"source":["# Verificar el modelo\n","!ls mejor_modelo_HDF5.h5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OGA02tY97EUI"},"source":["## 6.2. Carga de un modelo\n","\n","Se puede caargar un modelo grabado usando el método [`load_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model).\n","\n","El cargar un modelo para SavedModel o HDF5 se realiza de la misma manera"]},{"cell_type":"code","metadata":{"id":"FzyLIWfs7Fvh"},"source":["# Carga de un model a partir de un formato SavedModel\n","modelo_nuevo = tf.keras.models.load_model(\"mejor_modelo_SavedModel\")\n","modelo_nuevo.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rehN8ZxTy43"},"source":["# Comparación de los dos modelos (el cargado y el que se tiene en este notebook)\n","model_2_preds = model_2.predict(X_test)\n","modelo_nuevo_preds = modelo_nuevo.predict(X_test)\n","\n","# Comparando el MAE no debería haber errores\n","tf.metrics.mean_absolute_error(y_test, modelo_nuevo_preds.squeeze()).numpy() == tf.metrics.mean_absolute_error(y_test, model_2_preds.squeeze()).numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"prjkfX6rUZ6a"},"source":["*Carga del modelo en HDF5:*"]},{"cell_type":"code","metadata":{"id":"dQfx-bWKUfRQ"},"source":["modelo_h5 = tf.keras.models.load_model(\"mejor_modelo_HDF5.h5\")\n","modelo_h5.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0kT91h-Uru-"},"source":["# Comparación de ambos modelos\n","modelo_h5_preds = modelo_h5.predict(X_test)\n","\n","tf.metrics.mean_absolute_error(y_test, modelo_h5_preds.squeeze()).numpy() == tf.metrics.mean_absolute_error(y_test, model_2_preds.squeeze()).numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ABtsYBDtr5Zz"},"source":["**Descarga del modelo (de Google Colab)**\n","\n","Se puede utilizar cualquiera de las dos opciones siguientes:\n","* Hacer click derecho en el archivo y seleccionar'download'.\n","* Utilizar el siguiente código"]},{"cell_type":"code","metadata":{"id":"JV0onjIIr9XC"},"source":["from google.colab import files\n","\n","files.download(\"mejor_modelo_HDF5.h5\")"],"execution_count":null,"outputs":[]}]}